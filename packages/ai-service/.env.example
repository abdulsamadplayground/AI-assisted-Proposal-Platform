# Server Configuration
PORT=8000
HOST=0.0.0.0
ENVIRONMENT=development

# Backend URL
BACKEND_URL=http://localhost:3001

# LLM Provider Configuration
# Options: groq, openai, azure
LLM_PROVIDER=groq

# LLM Settings
LLM_MAX_RETRIES=3
LLM_TIMEOUT=30
LLM_MAX_TOKENS=500
LLM_TEMPERATURE=0.7

# Groq Configuration (default)
GROQ_API_KEY=your-groq-api-key-here
GROQ_MODEL=llama-3.3-70b-versatile

# OpenAI Configuration (if using OpenAI)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_API_BASE=https://api.openai.com/v1

# Azure OpenAI Configuration (if using Azure)
# AZURE_OPENAI_API_KEY=your-azure-api-key-here
# AZURE_OPENAI_ENDPOINT=your-azure-endpoint
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name
# AZURE_OPENAI_API_VERSION=2023-05-15

# Logging
LOG_LEVEL=INFO

# ========================================
# VERCEL PRODUCTION ENVIRONMENT VARIABLES
# ========================================
# Add these in Vercel Dashboard (Settings > Environment Variables):
#
# ENVIRONMENT=production
# BACKEND_URL=https://your-backend-domain.vercel.app
# GROQ_API_KEY=<your-actual-groq-api-key> (already added)
# LLM_PROVIDER=groq
# LOG_LEVEL=INFO
